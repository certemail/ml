{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading history matrix original dimensions:    (455, 34)\n",
      "assessment scores matrix original dimensions:  (453, 26)\n"
     ]
    }
   ],
   "source": [
    "# read in both datasets\n",
    "reading_history_df   = pd.read_csv(\"data/db/reading_history_database.csv\")\n",
    "assessment_scores_df = pd.read_csv(\"data/db/screening_assessment_scores.csv\")\n",
    "print(\"reading history matrix original dimensions:   \", reading_history_df.shape)\n",
    "print(\"assessment scores matrix original dimensions: \", assessment_scores_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reading_history duplicate keys:\n",
      "1161    2\n",
      "2019    2\n",
      "2234    2\n",
      "2575    2\n",
      "4744    2\n",
      "5343    2\n",
      "5559    2\n",
      "7806    2\n",
      "9010    2\n",
      "Name: Participant, dtype: int64\n",
      "pre-processed reading history matrix dimensions:  (433, 32)\n",
      "Participant     0\n",
      "Q1              0\n",
      "Q2              0\n",
      "Q3              0\n",
      "Q4              0\n",
      "Q5              0\n",
      "Q6              0\n",
      "Q7              0\n",
      "Q8              0\n",
      "Q9              0\n",
      "Q10             0\n",
      "Q11             0\n",
      "Q12             0\n",
      "Q13             0\n",
      "Q14             0\n",
      "Q15             0\n",
      "Q16             0\n",
      "Q17             0\n",
      "Q18             0\n",
      "Q19             0\n",
      "Q20             0\n",
      "Q21             0\n",
      "Q22             0\n",
      "Q23             0\n",
      "Q24             0\n",
      "Q25             0\n",
      "Q26             2\n",
      "Q27             1\n",
      "Q28            45\n",
      "Q29             0\n",
      "Q31             1\n",
      "Q33             1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# pre-process reading_history database\n",
    "\n",
    "# shorten the column names for readability\n",
    "shortened_cols = [\"Q\"+str(q) for q in range(1,34)]\n",
    "shortened_cols.insert(0, \"Participant\")\n",
    "reading_history_df.columns = shortened_cols\n",
    "\n",
    "# delete irrelevant columns (comments entered by subjects)\n",
    "del reading_history_df['Q30']\n",
    "del reading_history_df['Q32']\n",
    "\n",
    "# remove all NULL rows\n",
    "reading_history_df = reading_history_df.dropna(axis=0, how='all')\n",
    "\n",
    "# find and remove any duplicate keys ('Participant')    #df[~df.name.isin(value_list)]\n",
    "rd_h = reading_history_df['Participant'].value_counts()\n",
    "reading_history_duplicates = rd_h[rd_h > 1]\n",
    "print(\"\\nreading_history duplicate keys:\")\n",
    "print(reading_history_duplicates.sort_index())\n",
    "\n",
    "duplicate_participants_to_remove = reading_history_duplicates.index.tolist()\n",
    "reading_history_df = reading_history_df[~reading_history_df.Participant.isin(duplicate_participants_to_remove)]\n",
    "\n",
    "# remove row that has 'Participant' number as \"INCOMPLETE\"\n",
    "reading_history_df = reading_history_df[~reading_history_df.Participant.isin(['INCOMPLETE'])]\n",
    "\n",
    "print(\"pre-processed reading history matrix dimensions: \", reading_history_df.shape)\n",
    "print(reading_history_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assesment_scores duplicate keys:\n",
      "1161    2\n",
      "2019    2\n",
      "2234    2\n",
      "4744    2\n",
      "5343    2\n",
      "5559    2\n",
      "6970    2\n",
      "7806    2\n",
      "9010    2\n",
      "9379    2\n",
      "Name: Participant Number, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# pre-process assessment_scores\n",
    "as_s = assessment_scores_df['Participant Number'].value_counts()\n",
    "as_s = as_s[as_s > 1]\n",
    "\n",
    "print(\"\\nassesment_scores duplicate keys:\")\n",
    "print(as_s.sort_index())\n",
    "\n",
    "assessment_scores.rename(columns={ assessment_scores.columns[0]: \"Participant\" }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge 2 databases on 'Participant' as key into one\n",
    "merged_history_and_scores = pd.merge(reading_history, assessment_scores, how='inner', on='Participant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged history and scores dimensions:  (460, 56)\n"
     ]
    }
   ],
   "source": [
    "# reset 'Participant' as the index\n",
    "merged_history_and_scores.set_index('Participant', inplace=True)\n",
    "print(\"merged history and scores dimensions: \", merged_history_and_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop rows where all of the elements are NaN \n",
    "merged_history_and_scores = merged_history_and_scores.dropna(axis=0, how='all')\n",
    "#print(\"Number of missing values (NaN) by column:\")\n",
    "#print(merged_history_and_scores.isnull().sum())\n",
    "#print(\"\\nDimensions after dropping empty rows:\", merged_history_and_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE:\n",
      "all possible values in Q29:  ['No' 'Yes' 'Not Sure' 'Not sure' 'No ']\n",
      "value counts: \n",
      " No          335\n",
      "Yes          55\n",
      "Not sure     47\n",
      "Not Sure     21\n",
      "No            1\n",
      "Name: Q29, dtype: int64\n",
      "\n",
      "AFTER:\n",
      "all possible values in Q29:  ['no' 'yes' 'not_sure']\n",
      "value counts: \n",
      " no          336\n",
      "not_sure     68\n",
      "yes          55\n",
      "Name: Q29, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Q29 cleanup\n",
    "# make all lowercase and strip whitespace\n",
    "print(\"BEFORE:\")\n",
    "print(\"all possible values in Q29: \", merged_history_and_scores.Q29.unique())\n",
    "print(\"value counts: \\n\", merged_history_and_scores.Q29.value_counts())\n",
    "\n",
    "print(\"\\nAFTER:\")\n",
    "merged_history_and_scores['Q29'] = merged_history_and_scores['Q29'].apply(lambda x: x.lower().strip())\n",
    "\n",
    "def not_sure_add_underscore(x):\n",
    "    if x == 'not sure':\n",
    "        return('not_sure')\n",
    "    else:\n",
    "        return(x)\n",
    "merged_history_and_scores['Q29'] = merged_history_and_scores['Q29'].apply(not_sure_add_underscore) \n",
    "print(\"all possible values in Q29: \", merged_history_and_scores.Q29.unique())\n",
    "print(\"value counts: \\n\", merged_history_and_scores.Q29.value_counts())\n",
    "\n",
    "# create dummy set\n",
    "new_Q29 = pd.get_dummies(merged_history_and_scores['Q29'], prefix='Q29')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q31 cleanup: as unordered (yes, no, not sure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q33 cleanup: as ordered categories (\"some college, etc.\")\n",
    "#print(\"all possible values in Q33: \")\n",
    "#merged_history_and_scores.Q33.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
