import json
import glob
import os
import argparse
from collections import OrderedDict
from pprint import pprint


def enumerate_all_features(path_to_dataset):
    all_features_in_dataset = {}

    # recursively open all files
    for filename in glob.iglob(path_to_dataset + '/**/*.json', recursive=True):
        print("PROCESSING: " + filename)

        with open(filename) as data_file:
            data = json.load(data_file)

            # get all properties for this file
            properties = sorted((data["properties"]).keys())
            print("Properties: " + str(len(properties)))

            # add feature and values to dictionary
            for feature in properties:
                print("feature: " + feature)

                if not feature in all_features_in_dataset:
                    # create empty list as value if first time seeing feature
                    all_features_in_dataset[feature] =[] 
                    feature_values_str  = data["properties"][feature]
                    feature_values_list = [x for x in feature_values_str.split()]
                    for f_value in feature_values_list:
                        all_features_in_dataset[feature].append(f_value)

                else:
                    feature_values_str  = data["properties"][feature]
                    feature_values_list = [x for x in feature_values_str.split()]
                    for f_value in feature_values_list:
                        all_features_in_dataset[feature].append(f_value)

            print("-------------------------------------")

    # post procesing to remove duplicates 
    # convert to set (keep unique) and then back to list (sorted)
    for k, v in all_features_in_dataset.items():
        all_features_in_dataset[k] = sorted(list(set(v)))
        
    return all_features_in_dataset

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument("path_to_tng_data", help="full path to malware training data set")
    args = parser.parse_args()

    all_features = enumerate_all_features(args.path_to_tng_data)

    print("Total number of features in dataset: " + str(len(all_features.keys())))

    # write out all features and values in dataset to file
    with open("all_features_values.json", 'w') as outfile:
        outfile.write(json.dumps(all_features, sort_keys=True, indent=4))

